{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9264fba4",
   "metadata": {
    "cellUniqueIdByVincent": "7430a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the datasets\n",
    "real_data = pd.read_csv(\"./datasets/real-data-20250501-154339.csv\")\n",
    "synth_data = pd.read_csv(\"./datasets/synth.csv\")\n",
    "synth_data = synth_data.drop(columns=['id'])\n",
    "all_data = pd.concat([real_data, synth_data], ignore_index=True)\n",
    "# Generate profile reports\n",
    "profileInitialReal = ProfileReport(real_data, title=\"Real Data Profile Report\")\n",
    "profileInitialSynth = ProfileReport(synth_data, title=\"Synthetic Data Profile Report\")\n",
    "\n",
    "datasetsInitial = {}\n",
    "datasetsInitial[\"Real Data\"] = real_data\n",
    "datasetsInitial[\"Synthetic Data\"] = synth_data\n",
    "\n",
    "value_counts = real_data['NObeyesdad'].value_counts()\n",
    "print(value_counts)\n",
    "print(value_counts/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b12cc1",
   "metadata": {
    "cellUniqueIdByVincent": "66137"
   },
   "outputs": [],
   "source": [
    "raw_pseudoreal_data = pd.read_csv(\"./datasets/real-data-20250501-154339.csv\")\n",
    "\n",
    "# Split the data into actual real data and generated with SMOTE(pseudoreal)\n",
    "raw_real_data = raw_pseudoreal_data[0:477]\n",
    "raw_pseudoreal_data = raw_pseudoreal_data[478:]\n",
    "\n",
    "# Synthetic data generated using DeepLearning model\n",
    "raw_synthetic_data = pd.read_csv(\"./datasets/synth.csv\")\n",
    "raw_synthetic_data = raw_synthetic_data.drop(columns=['id'])\n",
    "\n",
    "# Generate profile reports\n",
    "profileRawReal = ProfileReport(raw_real_data, title=\"Raw Real Data Profile Report\")\n",
    "profileRawPseudoreal = ProfileReport(raw_pseudoreal_data, title=\"Raw Pseudoreal Data Profile Report\")\n",
    "profileRawSynth = ProfileReport(raw_synthetic_data, title=\"Raw Synthetic Data Profile Report\")\n",
    "\n",
    "datasetsExtra = {}\n",
    "datasetsExtra[\"Raw Real Data\"] = raw_real_data\n",
    "datasetsExtra[\"Raw Pseudoreal Data\"] = raw_pseudoreal_data\n",
    "datasetsExtra[\"Raw Synthetic Data\"] = raw_synthetic_data\n",
    "\n",
    "value_counts = raw_real_data['NObeyesdad'].value_counts()\n",
    "print(value_counts)\n",
    "print(value_counts/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfc0d12",
   "metadata": {
    "cellUniqueIdByVincent": "5cafd"
   },
   "outputs": [],
   "source": [
    "def display_data(df_name, df):\n",
    "    print(50*\"=\")\n",
    "    print(f\"dataset: {df_name} \\n\" + 50*\"-\")\n",
    "    print(f\"\\nShape of {df_name}:\\n\" + 50*\"-\")\n",
    "    display(df.shape)\n",
    "    print(f\"\\ndataset info {df_name}:\\n\" + 50*\"-\")\n",
    "    display(df.info())\n",
    "    \n",
    "    print(f\"\\nhead and tail of {df_name}:\\n\" + 50*\"-\")\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    \n",
    "    print(f\"\\ndescribe {df_name}:\\n\" + 50*\"-\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    print(f\"\\nMissing Values in {df_name}:\\n\" + 50 * \"-\")\n",
    "    display(df.isnull().sum())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f80ae",
   "metadata": {
    "cellUniqueIdByVincent": "051a1"
   },
   "source": [
    "## Displaying basic data value\n",
    "to get a basic idea how the data is consisting of and to see if there are any missing values, what kind of datatypes we have and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d199455c",
   "metadata": {
    "cellUniqueIdByVincent": "1ab77"
   },
   "outputs": [],
   "source": [
    "\n",
    "for df_name, df in datasetsInitial.items():\n",
    "    display_data(df_name, df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a36f89",
   "metadata": {
    "cellUniqueIdByVincent": "53aff"
   },
   "source": [
    "## Profile reports\n",
    "we are displaying both profile reports, to have a look at correlations matrices, key patterns and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7da4",
   "metadata": {
    "cellUniqueIdByVincent": "e2100"
   },
   "outputs": [],
   "source": [
    "# Display the reports\n",
    "display(profileInitialReal)\n",
    "display(profileInitialSynth)\n",
    "display(profileRawReal)\n",
    "display(profileRawPseudoreal)\n",
    "display(profileRawSynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c28c9",
   "metadata": {
    "cellUniqueIdByVincent": "a5a23"
   },
   "source": [
    "gender tarogt on obesity 2 and obesity 3 are badly distributed, maybe we just bin them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfae5bf",
   "metadata": {
    "cellUniqueIdByVincent": "c2594"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ordered_categories = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f95ef5",
   "metadata": {
    "cellUniqueIdByVincent": "4bdd8"
   },
   "source": [
    "## Understanding the data Distribution\n",
    "firstly we create functions the plot different data distributions, to see how features are distributed in regards to the target, since we have the assumption that synthetical data (Smote and Synth) have strange distributions, because of the data they originate from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7667d129",
   "metadata": {
    "cellUniqueIdByVincent": "53fdb"
   },
   "outputs": [],
   "source": [
    "def plot_stacked_bars_multiple_dfs(dfs, df_names, target, feature, title, ordered_categories = None, ncols=2):\n",
    "    \"\"\"\n",
    "    Plot stacked bar charts for the same feature across multiple DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - dfs: List of DataFrames to plot.\n",
    "    - df_names: List of names for each DataFrame (for titles).\n",
    "    - target: The target column name.\n",
    "    - feature: The feature column name to plot.\n",
    "    - title: The title for the whole plot.\n",
    "    - ncols: Number of columns in the plot grid (default is 2).\n",
    "    \"\"\"\n",
    "            \n",
    "    # Calculate the number of rows needed\n",
    "    nrows = (len(dfs) + ncols - 1) // ncols\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12 * ncols, 8 * nrows))\n",
    "    fig.suptitle(f'Stacked Distribution of {feature} on {title}', fontsize=24, y=1.05)\n",
    "\n",
    "    # Flatten the axes array for easy indexing\n",
    "    axes = axes.flatten() if len(dfs) > 1 else [axes]\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if(feature == 'family_history'):\n",
    "            feature = 'family_history_with_overweight'\n",
    "            \n",
    "        if(df_copy[feature].dtype == 'float64'):\n",
    "            df_copy[feature] = df_copy[feature].round()\n",
    "            \n",
    "            \n",
    "        # Create a DataFrame with counts of the feature for each target category\n",
    "        counts_df = df_copy.groupby([target, feature]).size().unstack(fill_value=0)\n",
    "\n",
    "        # Reorder the DataFrame according to the specified order of categories\n",
    "        counts_df = counts_df.reindex(ordered_categories)\n",
    "        if(feature == 'family_history_with_overweight'):\n",
    "            feature = 'family_history'\n",
    "            \n",
    "        # Plot the stacked bar plot\n",
    "        counts_df.plot(kind='bar', stacked=True, ax=axes[i], colormap='coolwarm') # color=['#ff9999', '#66b3ff']\n",
    "        axes[i].set_title(df_names[i])\n",
    "        axes[i].set_ylabel(f'Counts of {feature} Levels')\n",
    "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
    "        axes[i].legend(title=f'{feature} Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Remove empty subplots if the number of dataframes is less than the number of subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0545018",
   "metadata": {
    "cellUniqueIdByVincent": "b1531"
   },
   "source": [
    "function for boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4485c74f",
   "metadata": {
    "cellUniqueIdByVincent": "f5fa1"
   },
   "outputs": [],
   "source": [
    "def plot_boxplots_multiple_dfs(dfs, df_names, target, feature, title, ncols=2):\n",
    "    \"\"\"\n",
    "    Plot stacked bar charts for the same feature across multiple DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - dfs: List of DataFrames to plot.\n",
    "    - df_names: List of names for each DataFrame (for titles).\n",
    "    - target: The target column name.\n",
    "    - feature: The feature column name to plot.\n",
    "    - title: The title for the whole plot.\n",
    "    - ncols: Number of columns in the plot grid (default is 2).\n",
    "    \"\"\"\n",
    "            \n",
    "    # Calculate the number of rows needed\n",
    "    nrows = (len(dfs) + ncols - 1) // ncols\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12 * ncols, 8 * nrows))\n",
    "    fig.suptitle(f'Stacked Distribution of {feature} on {title}', fontsize=24, y=1.05)\n",
    "\n",
    "    # Flatten the axes array for easy indexing\n",
    "    axes = axes.flatten() if len(dfs) > 1 else [axes]\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "                        \n",
    "        if i >= len(axes):\n",
    "            break\n",
    "\n",
    "        # Plot the stacked bar plot\n",
    "        sns.boxplot(x=target, y=feature, data=df, ax=axes[i], order=ordered_categories, color='lightgrey')\n",
    "        axes[i].set_title(df_names[i])\n",
    "        axes[i].set_xlabel(f'{target} Categories')\n",
    "        axes[i].set_ylabel(f'Counts of {feature} Levels')\n",
    "        axes[i].set_xticks(range(len(ordered_categories)))\n",
    "        axes[i].set_xticklabels(ordered_categories, rotation=45)\n",
    "\n",
    "    # Remove empty subplots if the number of dataframes is less than the number of subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bd65e",
   "metadata": {
    "cellUniqueIdByVincent": "b8aef"
   },
   "source": [
    "displaying all the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670548bc",
   "metadata": {
    "cellUniqueIdByVincent": "7cc46"
   },
   "outputs": [],
   "source": [
    "df_names_initial = ()\n",
    "dfs_initial = ()\n",
    "for df_name, df in datasetsInitial.items():\n",
    "    df_names_initial = df_names_initial + (df_name,)\n",
    "    dfs_initial = dfs_initial  + (df,)\n",
    "\n",
    "df_names_extra = ()\n",
    "dfs_extra = ()\n",
    "for df_name, df in datasetsExtra.items():\n",
    "    df_names_extra = df_names_extra + (df_name,)\n",
    "    dfs_extra = dfs_extra + (df,)\n",
    "    \n",
    "df_features_for_stacking = ('Gender', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'CALC','SCC')\n",
    "\n",
    "df_features_for_boxplot = ('Height', 'Weight', 'Age')\n",
    "\n",
    "for feature in df_features_for_stacking:\n",
    "    plot_stacked_bars_multiple_dfs(dfs_initial, df_names_initial, 'NObeyesdad', feature, 'Initial Approach', ordered_categories)\n",
    "    plot_stacked_bars_multiple_dfs(dfs_extra, df_names_extra, 'NObeyesdad', feature, 'Extra Approach', ordered_categories, ncols=3)\n",
    "\n",
    "for feature in df_features_for_boxplot:\n",
    "    plot_boxplots_multiple_dfs(dfs_initial, df_names_initial, 'NObeyesdad', feature, 'Initial Approach')\n",
    "    plot_boxplots_multiple_dfs(dfs_extra, df_names_extra, 'NObeyesdad', feature, 'Extra Approach', ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470a734",
   "metadata": {
    "cellUniqueIdByVincent": "72d48"
   },
   "source": [
    "## Plotting features\n",
    "plotting interesting features from the ProfileReport, to see how they correlate and get a better understanding of their interaction and if it changes between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24b3b10",
   "metadata": {
    "cellUniqueIdByVincent": "5aab4"
   },
   "outputs": [],
   "source": [
    "def plot_scatterplot_multiple_dfs(dfs, df_names, feature_0, feature_1, title):\n",
    "    \"\"\"\n",
    "    Plot scatter plots for the same feature across multiple DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - dfs: List of DataFrames to plot.\n",
    "    - df_names: List of names for each DataFrame (for titles).\n",
    "    - target: The target column name.\n",
    "    - feature: The feature column name to plot.\n",
    "    - title: The title for the whole plot.\n",
    "    - ncols: Number of columns in the plot grid (default is 2).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predefined color mapping for consistency\n",
    "    fixed_colors = {\n",
    "        'Normal_Weight': '#1f77b4',       # Blue\n",
    "        'Overweight_Level_I': '#ff7f0e',  # Orange\n",
    "        'Overweight_Level_II': '#2ca02c', # Green\n",
    "        'Obesity_Type_I': '#d62728',      # Red\n",
    "        'Obesity_Type_II': '#9467bd',     # Purple\n",
    "        'Obesity_Type_III': '#8c564b',    # Brown\n",
    "        'Insufficient_Weight': '#e377c2'  # Pink\n",
    "    }\n",
    "    \n",
    "    # Calculate the number of rows needed\n",
    "    ncols = len(dfs)\n",
    "    nrows = 1\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols, 6))\n",
    "    fig.suptitle(f'Scatterplot of {feature_1} and {feature_0} w.r.t. Obesity Categories \\n on {title}', fontsize=24, y=1.05)\n",
    "\n",
    "    # Flatten the axes array for easy indexing\n",
    "    axes = axes.flatten() if len(dfs) > 1 else [axes]\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "                        \n",
    "        if i >= len(axes):\n",
    "            break\n",
    "\n",
    "        # Plot the scatter plot\n",
    "        sns.scatterplot(\n",
    "            x=feature_0, y=feature_1, hue=df['NObeyesdad'], hue_order=ordered_categories,\n",
    "            data=df, ax=axes[i], palette = fixed_colors, alpha=0.7\n",
    "            )\n",
    "        axes[i].set_title(df_names[i])\n",
    "        axes[i].set_xlabel(f'{feature_0}')\n",
    "        axes[i].set_ylabel(f'{feature_1}')\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    # Remove empty subplots if the number of dataframes is less than the number of subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb596ff",
   "metadata": {
    "cellUniqueIdByVincent": "0211a"
   },
   "outputs": [],
   "source": [
    "df_features_for_scattering = (('Age', 'Height'),('Age', 'Weight'),('Height', 'Weight'),('FCVC','Gender'),('FAF','Height'),('Age','TUE'),('Gender','FAVC'),('NCP','family_history_with_overweight'))\n",
    "\n",
    "for feature in df_features_for_scattering:\n",
    "    plot_scatterplot_multiple_dfs(dfs_initial, df_names_initial, feature[0], feature[1], 'Initial Approach')\n",
    "    plot_scatterplot_multiple_dfs(dfs_extra, df_names_extra, feature[0], feature[1], 'Extra Approach')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff55e9",
   "metadata": {
    "cellUniqueIdByVincent": "ff531"
   },
   "source": [
    "## Duplicates\n",
    "9 instances are duplicated for 33 times, which is within 1% of the entire dataset and we decided to keep the values, since we assume that there are people who have the same body features and lifestyles.\n",
    "We have a heavily underrepresented data for example in Overweight_I, the duplicates are actually SMOTE values from the heavily underrepresented targets. Since the SMOTE values are a linear combination of K nearest neighbours and since there are not so many different values the neighbours are going to be alot of the time the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c244533",
   "metadata": {
    "cellUniqueIdByVincent": "0be3b"
   },
   "outputs": [],
   "source": [
    "# Print duplicated rows from real dataset\n",
    "duplicatedRows = real_data[real_data.duplicated(keep=False)]\n",
    "print(duplicatedRows)\n",
    "print(f\"Total number of duplicate entries (including repeated instances): {len(duplicatedRows)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290be962",
   "metadata": {
    "cellUniqueIdByVincent": "72b9d"
   },
   "source": [
    "display extra datasets"
   ]
  }
 ],
 "metadata": {
  "vincent": {
   "sessionId": "9959b92de49a3798cbb1afec_2025-05-17T13-04-39-459Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
