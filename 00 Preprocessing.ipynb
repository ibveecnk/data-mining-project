{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "6bc7a22de2944b12b7bf2be0afb6553c",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 811,
    "execution_start": 1746631708334,
    "source_hash": "eb868225"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gower\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "09186cd7ab434177839cac0383c28c32",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 1,
    "execution_start": 1746631709215,
    "source_hash": "f0b884f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- Move gender to ONE HOT\\n- Move Age to NUMERICAL\\n- Remove Weight\\n\\nTODO:\\n- Round age, height, weight\\n- Integer Round FCVC, NCP, CH20, FAF, TUE\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Features:\n",
    "\n",
    " #   Column                          Non-Null Count  Dtype  \n",
    "---  ------                          --------------  -----  \n",
    " 0   Gender                          2111 non-null   object \n",
    " 1   Age                             2111 non-null   float64\n",
    " 2   Height                          2111 non-null   float64\n",
    " 2   family_history_with_overweight  2111 non-null   object \n",
    " 3   FAVC                            2111 non-null   object \n",
    " 4   FCVC                            2111 non-null   float64\n",
    " 5   NCP                             2111 non-null   float64\n",
    " 6   CAEC                            2111 non-null   object \n",
    " 7   SMOKE                           2111 non-null   object \n",
    " 8   CH2O                            2111 non-null   float64\n",
    " 9   SCC                             2111 non-null   object \n",
    " 10  FAF                             2111 non-null   float64\n",
    " 11  TUE                             2111 non-null   float64\n",
    " 12  CALC                            2111 non-null   object \n",
    " 13  MTRANS                          2111 non-null   object \n",
    " 14  NObeyesdad                      2111 non-null   object \n",
    "\"\"\"\n",
    "\n",
    "# Keep only specified features and remove Unnamed and Height/Weight columns\n",
    "COLUMNS_TO_KEEP = [\n",
    "    'Gender', 'Age', 'Height', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP',\n",
    "    'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'NObeyesdad'\n",
    "]\n",
    "AGE_FEATURE = ['Age']\n",
    "GENDER_FEATURE = []\n",
    "NUMERICAL_FEATURES = ['Height']\n",
    "BOOLEAN_FEATURES = ['family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
    "ORDINAL_FEATURES = ['CAEC', 'CALC']\n",
    "INTEGER_FEATURES = ['FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "ONE_HOT_FEATURES = ['MTRANS', 'Gender'] #dont want to drop the first column thats why its not all in one array\n",
    "\n",
    "\"\"\"\n",
    "- Move gender to ONE HOT\n",
    "- Move Age to NUMERICAL\n",
    "- Remove Weight\n",
    "\n",
    "TODO:\n",
    "- Round age, height, weight\n",
    "- Integer Round FCVC, NCP, CH20, FAF, TUE\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "7b805c17835646fbb249ccb86f5e8161",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 0,
    "execution_start": 1746631709264,
    "source_hash": "ef234641"
   },
   "outputs": [],
   "source": [
    "## Gower distance\n",
    "# Main function to remove similarities\n",
    "def remove_similar(X_test, synth, threshold=.2):\n",
    "    to_remove = []\n",
    "    removed_map = {}\n",
    "\n",
    "    for i, row in X_test.iterrows():\n",
    "        # Compute Gower distance between the real record and the synthetic data\n",
    "        gower_matrix = gower.gower_matrix(row.to_frame().T, synth)\n",
    "        # Find indices of synthetic records within the threshold\n",
    "        matches = np.where(gower_matrix <= threshold)\n",
    "        unique_indices = np.unique(matches[1])\n",
    "        \n",
    "        # Save the indices of the removed records\n",
    "        for idx in unique_indices:\n",
    "            removed_map.setdefault(idx, []).append(i)\n",
    "\n",
    "        # Save removed indices for later analysis (number of removed records)    \n",
    "        to_remove.extend(unique_indices)\n",
    "    \n",
    "    # Remove found similarities from synthetic data\n",
    "    synth = synth.drop(index=to_remove)\n",
    "\n",
    "    # print(f\"Number of unique indices to remove: {len(np.unique(to_remove))}\")\n",
    "    # print(f\"Length of synth before: {len(synth_raw)}\")\n",
    "    # print(f\"Length of synth after: {len(synth)}\")\n",
    "    # print(f\"Total synth rows removed: {len(synth_raw) - len(synth)}\")\n",
    "\n",
    "    return synth, removed_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "c660a27ff2af45aebf525d1dd7df941d",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 18548,
    "execution_start": 1746631709314,
    "source_hash": "634c2f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: pseudoreal\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1633 entries, 478 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          1633 non-null   object \n",
      " 1   Age                             1633 non-null   float64\n",
      " 2   Height                          1633 non-null   float64\n",
      " 3   Weight                          1633 non-null   float64\n",
      " 4   family_history_with_overweight  1633 non-null   object \n",
      " 5   FAVC                            1633 non-null   object \n",
      " 6   FCVC                            1633 non-null   float64\n",
      " 7   NCP                             1633 non-null   float64\n",
      " 8   CAEC                            1633 non-null   object \n",
      " 9   SMOKE                           1633 non-null   object \n",
      " 10  CH2O                            1633 non-null   float64\n",
      " 11  SCC                             1633 non-null   object \n",
      " 12  FAF                             1633 non-null   float64\n",
      " 13  TUE                             1633 non-null   float64\n",
      " 14  CALC                            1633 non-null   object \n",
      " 15  MTRANS                          1633 non-null   object \n",
      " 16  NObeyesdad                      1633 non-null   object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 217.0+ KB\n",
      "None\n",
      "Dataset type: real\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 477 entries, 0 to 476\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          477 non-null    object \n",
      " 1   Age                             477 non-null    float64\n",
      " 2   Height                          477 non-null    float64\n",
      " 3   Weight                          477 non-null    float64\n",
      " 4   family_history_with_overweight  477 non-null    object \n",
      " 5   FAVC                            477 non-null    object \n",
      " 6   FCVC                            477 non-null    float64\n",
      " 7   NCP                             477 non-null    float64\n",
      " 8   CAEC                            477 non-null    object \n",
      " 9   SMOKE                           477 non-null    object \n",
      " 10  CH2O                            477 non-null    float64\n",
      " 11  SCC                             477 non-null    object \n",
      " 12  FAF                             477 non-null    float64\n",
      " 13  TUE                             477 non-null    float64\n",
      " 14  CALC                            477 non-null    object \n",
      " 15  MTRANS                          477 non-null    object \n",
      " 16  NObeyesdad                      477 non-null    object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 63.5+ KB\n",
      "None\n",
      "Dataset type: synthetic\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20758 entries, 0 to 20757\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          20758 non-null  object \n",
      " 1   Age                             20758 non-null  float64\n",
      " 2   Height                          20758 non-null  float64\n",
      " 3   Weight                          20758 non-null  float64\n",
      " 4   family_history_with_overweight  20758 non-null  object \n",
      " 5   FAVC                            20758 non-null  object \n",
      " 6   FCVC                            20758 non-null  float64\n",
      " 7   NCP                             20758 non-null  float64\n",
      " 8   CAEC                            20758 non-null  object \n",
      " 9   SMOKE                           20758 non-null  object \n",
      " 10  CH2O                            20758 non-null  float64\n",
      " 11  SCC                             20758 non-null  object \n",
      " 12  FAF                             20758 non-null  float64\n",
      " 13  TUE                             20758 non-null  float64\n",
      " 14  CALC                            20758 non-null  object \n",
      " 15  MTRANS                          20758 non-null  object \n",
      " 16  NObeyesdad                      20758 non-null  object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Load the datasets\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "raw_pseudoreal_data = pd.read_csv(\"./datasets/real-data-20250501-154339.csv\")\n",
    "raw_real_data = raw_pseudoreal_data[0:477] # as in the paper\n",
    "raw_pseudoreal_data = raw_pseudoreal_data[478:]\n",
    "\n",
    "synthetic_data = pd.read_csv(\"./synth.csv\")\n",
    "synthetic_data = synthetic_data.drop(columns=['id'])\n",
    "real_test_gower = train_test_split(raw_real_data, test_size=TEST_SIZE, random_state=42, stratify=raw_real_data['NObeyesdad'])\n",
    "raw_synthetic_data, removed_map = remove_similar(real_test_gower[0], synthetic_data)\n",
    "\n",
    "raw_synthetic_data = synthetic_data\n",
    "\n",
    "# raw_synthetic_data = pd.concat([raw_pseudoreal_data, raw_synthetic_data])\n",
    "\n",
    "RAW_DATA = {\n",
    "    'pseudoreal': raw_pseudoreal_data,\n",
    "    'real': raw_real_data,\n",
    "    'synthetic': raw_synthetic_data\n",
    "}\n",
    "\n",
    "for dataset_type, data in RAW_DATA.items():\n",
    "    print(f\"Dataset type: {dataset_type}\")\n",
    "    print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "39ca6fc01452464e96225a46d3bb08f1",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 228,
    "execution_start": 1746631727934,
    "source_hash": "b182e836"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# yes/no to 1/0\n",
    "class BooleanToBinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# made a custom mapper to have control over value\n",
    "class GenderToBinaryTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column='Gender'):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.column] = X[self.column].map({'Male': 0, 'Female': 1})\n",
    "        return X\n",
    "\n",
    "#made a custom mapper to have control over value\n",
    "class OrdinalMapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mapping = {\n",
    "            'no': 0,\n",
    "            'Sometimes': 1,\n",
    "            'Frequently': 2,\n",
    "            'Always': 3\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X = X.copy()\n",
    "        # # Apply the mapping to all specified columns\n",
    "        # for col, mapping in self.mapping.items():\n",
    "        #     if col in X.columns:\n",
    "        #         X[col] = X[col].map(mapping)\n",
    "        return X.replace({\n",
    "            'no': 0,\n",
    "            'Sometimes': 1,\n",
    "            'Frequently': 2,\n",
    "            'Always': 3\n",
    "        })\n",
    "\n",
    "freq_map = {\n",
    "    'no': 0,\n",
    "    'Sometimes': 1,\n",
    "    'Frequently': 2,\n",
    "    'Always': 3\n",
    "}\n",
    "\n",
    "#Pipeline for Age\n",
    "round_then_scale = Pipeline([\n",
    "    ('round', FunctionTransformer(np.round, validate=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# ('gender', GenderToBinaryTransformer(), ['Gender']),\n",
    "# Combine all transformers into one preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age', StandardScaler(), ['Age']), # was round_then_scale\n",
    "        ('height', StandardScaler(), NUMERICAL_FEATURES),\n",
    "        ('bool', BooleanToBinaryTransformer(), BOOLEAN_FEATURES),\n",
    "        ('ordinal', OrdinalMapper(), ORDINAL_FEATURES),\n",
    "        ('int', FunctionTransformer(np.round, validate=False), INTEGER_FEATURES),\n",
    "        ('one-hot', OneHotEncoder(sparse_output=False, drop=\"if_binary\"), ONE_HOT_FEATURES)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "d564a0ddd0c54d61b82bb32d7dc778cc",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 0,
    "execution_start": 1746631728214,
    "source_hash": "998dac75"
   },
   "outputs": [],
   "source": [
    "#TODO update\n",
    "def get_final_feature_names(preprocessor, X_df):\n",
    "    \"\"\"\n",
    "    Reconstructs the full list of feature names after transformation.\n",
    "\n",
    "    Parameters:\n",
    "        preprocessor: the fitted ColumnTransformer\n",
    "        X_df: the original unprocessed DataFrame (e.g., X_train)\n",
    "        age, gender, boolean_features, ordinal_features, integer_features, one_hot_features: lists of assigned features\n",
    "\n",
    "    Returns:\n",
    "        A list of final feature names in the order they appear in the transformed array\n",
    "    \"\"\"\n",
    "    #return variable\n",
    "    final_feature_names = []\n",
    "\n",
    "\n",
    "    #Assigned features\n",
    "    assigned_features = AGE_FEATURE + GENDER_FEATURE + NUMERICAL_FEATURES + BOOLEAN_FEATURES + ORDINAL_FEATURES + INTEGER_FEATURES + ONE_HOT_FEATURES\n",
    "    print(f\"Assigned features ({len(assigned_features)}): {assigned_features}\")\n",
    "\n",
    "\n",
    "    #Passthrough features (not transformed)\n",
    "    all_features = list(X_df.columns)\n",
    "    passthrough_features = []\n",
    "    #f for f in all_features if f not in assigned_features\n",
    "\n",
    "    # for loop, so that the column names can be assigned as the preprocessor transformed them\n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        \n",
    "        # Handle each transformer according to its type\n",
    "        if name == 'age':\n",
    "            final_feature_names.extend(AGE_FEATURE)\n",
    "\n",
    "        elif name == 'height':\n",
    "            final_feature_names.extend(NUMERICAL_FEATURES)\n",
    "        \n",
    "        elif name == 'gender':\n",
    "            final_feature_names.extend(GENDER_FEATURE)\n",
    "        \n",
    "        elif name == 'bool':\n",
    "            final_feature_names.extend(BOOLEAN_FEATURES)\n",
    "        \n",
    "        elif name == 'ordinal':\n",
    "            final_feature_names.extend(ORDINAL_FEATURES)\n",
    "        \n",
    "        elif name == 'int':\n",
    "            final_feature_names.extend(INTEGER_FEATURES)\n",
    "        \n",
    "        elif name == 'one-hot':\n",
    "            cat_ohe = preprocessor.named_transformers_['one-hot']\n",
    "            cat_feature_names = cat_ohe.get_feature_names_out(ONE_HOT_FEATURES)\n",
    "            print(cat_feature_names)\n",
    "            final_feature_names.extend(cat_feature_names)\n",
    "\n",
    "    final_feature_names.extend(passthrough_features)\n",
    "\n",
    "    return final_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "21208a74cf0040799c28ca340061de3c",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 0,
    "execution_start": 1746631728275,
    "source_hash": "d8c84b41"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocess the data\n",
    "X_real = raw_real_data.drop(columns=['NObeyesdad'])\n",
    "y_real = raw_real_data['NObeyesdad']\n",
    "\n",
    "# Real Real data 477, splitted\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_real, y_real, test_size=TEST_SIZE, random_state=42, stratify=y_real)\n",
    "\n",
    "# Only pseudoreal data ~1666\n",
    "X_pseudoreal = raw_pseudoreal_data.drop(columns=['NObeyesdad'])\n",
    "y_pseudoreal = raw_pseudoreal_data['NObeyesdad']\n",
    "\n",
    "# Only synthetic data ~20k\n",
    "X_synth = raw_synthetic_data.drop(columns=['NObeyesdad'])\n",
    "y_synth = raw_synthetic_data['NObeyesdad']\n",
    "\n",
    "# Pseudoreal + real-real train\n",
    "X_pseudoreal_real = pd.concat([X_train_real, X_pseudoreal])\n",
    "y_pseudoreal_real = pd.concat([y_train_real, y_pseudoreal])\n",
    "\n",
    "# Pseudoreal + real + synthetic\n",
    "X_synth_pseudoreal_real = pd.concat([X_pseudoreal_real, X_synth])\n",
    "Y_synth_pseudoreal_real = pd.concat([y_pseudoreal_real, y_synth])\n",
    "\n",
    "test_data = {\n",
    "    'X': X_test_real,\n",
    "    'y': y_test_real\n",
    "}\n",
    "\n",
    "\n",
    "real_real_data = {\n",
    "    'X': X_train_real,\n",
    "    'y': y_train_real,\n",
    "}\n",
    "\n",
    "real_pseudoreal_data = {\n",
    "    'X': X_pseudoreal_real,\n",
    "    'y': y_pseudoreal_real,\n",
    "}\n",
    "\n",
    "synthetic_pseudoreal_data = {\n",
    "    'X': X_synth_pseudoreal_real,\n",
    "    'y': Y_synth_pseudoreal_real,\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    X = pd.DataFrame(preprocessor.fit_transform(data['X']), columns=get_final_feature_names(preprocessor, data['X']))\n",
    "    print(X.shape)\n",
    "\n",
    "    # y = pd.DataFrame(preprocessor.transform(data['y']), columns=get_final_feature_names(preprocessor, data['y'], AGE_FEATURE, GENDER_FEATURE, BOOLEAN_FEATURES, ORDINAL_FEATURES, INTEGER_FEATURES, ONE_HOT_FEATURES))\n",
    "    # print(y.shape)\n",
    "\n",
    "    return {\n",
    "        'X': X,\n",
    "        'y': data['y']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "bdb31eaab604441a87d7b0c47110b920",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 121,
    "execution_start": 1746631728334,
    "source_hash": "f80be9ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned features (15): ['Age', 'Height', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'CAEC', 'CALC', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'MTRANS', 'Gender']\n",
      "['MTRANS_Automobile' 'MTRANS_Bike' 'MTRANS_Motorbike'\n",
      " 'MTRANS_Public_Transportation' 'MTRANS_Walking' 'Gender_Male']\n",
      "(381, 19)\n",
      "Assigned features (15): ['Age', 'Height', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'CAEC', 'CALC', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'MTRANS', 'Gender']\n",
      "['MTRANS_Automobile' 'MTRANS_Bike' 'MTRANS_Motorbike'\n",
      " 'MTRANS_Public_Transportation' 'MTRANS_Walking' 'Gender_Male']\n",
      "(2014, 19)\n",
      "Assigned features (15): ['Age', 'Height', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'CAEC', 'CALC', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'MTRANS', 'Gender']\n",
      "['MTRANS_Automobile' 'MTRANS_Bike' 'MTRANS_Motorbike'\n",
      " 'MTRANS_Public_Transportation' 'MTRANS_Walking' 'Gender_Male']\n",
      "(22772, 19)\n",
      "Assigned features (15): ['Age', 'Height', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC', 'CAEC', 'CALC', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'MTRANS', 'Gender']\n",
      "['MTRANS_Automobile' 'MTRANS_Bike' 'MTRANS_Motorbike'\n",
      " 'MTRANS_Public_Transportation' 'MTRANS_Walking' 'Gender_Male']\n",
      "(96, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135938/1246266709.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "/tmp/ipykernel_135938/1246266709.py:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({\n",
      "/tmp/ipykernel_135938/1246266709.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "/tmp/ipykernel_135938/1246266709.py:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({\n",
      "/tmp/ipykernel_135938/1246266709.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "/tmp/ipykernel_135938/1246266709.py:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({\n",
      "/tmp/ipykernel_135938/1246266709.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "/tmp/ipykernel_135938/1246266709.py:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({\n"
     ]
    }
   ],
   "source": [
    "# Check if features are equal, otherwise insert 0 in place for missing features\n",
    "PROCESSED_DATA = {\n",
    "    'real': preprocess(real_real_data),\n",
    "    'pseudoreal': preprocess(real_pseudoreal_data),\n",
    "    'synthetic': preprocess(synthetic_pseudoreal_data),\n",
    "    'test': preprocess(test_data)\n",
    "}\n",
    "\n",
    "# # Get all unique columns from both datasets\n",
    "# all_columns = None\n",
    "\n",
    "# for dataset_type in PROCESSED_DATA.keys():\n",
    "#     if all_columns is None:\n",
    "#         all_columns = set(PROCESSED_DATA[dataset_type]['X_train'].columns)\n",
    "#     else:\n",
    "#         all_columns = all_columns.intersection(set(PROCESSED_DATA[dataset_type]['X_train'].columns))\n",
    "\n",
    "\n",
    "# # Add missing columns with zeros to both datasets\n",
    "# for dataset_type in PROCESSED_DATA.keys():\n",
    "#     for split in ['X_train', 'X_test']:\n",
    "#         missing_cols = all_columns - set(A[dataset_type][split].columns)\n",
    "#         for col in missing_cols:\n",
    "#             PROCESSED_DATA[dataset_type][split][col] = 0\n",
    "            \n",
    "#         # Ensure columns are in the same order\n",
    "#         PROCESSED_DATA[dataset_type][split] = PROCESSED_DATA[dataset_type][split][sorted(all_columns)]\n",
    "\n",
    "# # Verify that columns are now equal\n",
    "# for dataset_type in PROCESSED_DATA.keys():\n",
    "#     assert set(PROCESSED_DATA[dataset_type]['X_train'].columns) == set(PROCESSED_DATA[dataset_type]['X_test'].columns)\n",
    "\n",
    "# print(\"Features are now aligned between real and synthetic datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "8f1d97d5cc1e4c819ba953ca538e5191",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 4202,
    "execution_start": 1746631728505,
    "source_hash": "bdc1d9c6"
   },
   "outputs": [],
   "source": [
    "# Write the processed data to CSV\n",
    "\n",
    "PATH_PREFIX = './datasets/preprocessed/'\n",
    "\n",
    "for name, data in PROCESSED_DATA.items():\n",
    "    data['X'].to_csv(PATH_PREFIX + name + '_X.csv', index=False)\n",
    "    data['y'].to_csv(PATH_PREFIX + name + '_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "6f42364f3b21402d96985e9945ecf3b0",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 0,
    "execution_start": 1746631732778,
    "source_hash": "b623e53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between test set and real set:\n",
      "Age      -1.094488\n",
      "Height   -0.010535\n",
      "Weight   -0.563279\n",
      "FCVC      0.083497\n",
      "NCP      -0.007710\n",
      "CH2O     -0.067339\n",
      "FAF      -0.032644\n",
      "TUE       0.065289\n",
      "dtype: float64\n",
      "Difference between test set and pseudoreal set:\n",
      "Age       -2.305919\n",
      "Height    -0.028281\n",
      "Weight   -22.261665\n",
      "FCVC      -0.049115\n",
      "NCP       -0.049427\n",
      "CH2O      -0.143311\n",
      "FAF        0.182736\n",
      "TUE        0.050186\n",
      "dtype: float64\n",
      "Difference between test set and synthetic set:\n",
      "Age       -1.508471\n",
      "Height    -0.022328\n",
      "Weight   -18.617977\n",
      "FCVC      -0.050075\n",
      "NCP       -0.115499\n",
      "CH2O      -0.144002\n",
      "FAF        0.164087\n",
      "TUE        0.091577\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_test = X_test_real.mean(numeric_only=True)\n",
    "\n",
    "mean_real = X_train_real.mean(numeric_only=True)\n",
    "mean_pseudoreal = X_pseudoreal.mean(numeric_only=True)\n",
    "mean_synthetic = X_synth.mean(numeric_only=True)\n",
    "\n",
    "print(\"Difference between test set and real set:\")\n",
    "print(mean_test - mean_real)\n",
    "\n",
    "print(\"Difference between test set and pseudoreal set:\")\n",
    "print(mean_test - mean_pseudoreal)\n",
    "\n",
    "print(\"Difference between test set and synthetic set:\")\n",
    "print(mean_test - mean_synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a441f35e-4b4c-4c50-b56a-1aea6b800ed8' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "0ec939f6c6254f268bdbfe8da466167e",
  "deepnote_persisted_session": {
   "createdAt": "2025-05-07T15:51:40.796Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
