{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6bc7a22de2944b12b7bf2be0afb6553c",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 811,
    "execution_start": 1746631708334,
    "source_hash": "eb868225"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gower\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets\n",
    "We load the datasets, we decided to split them into 3 different datasets and concatenate them later on based the use case. The concatination step is done before any preprocessing.\n",
    "\n",
    "TODO from 12.05.2025 21:54 (add more and when chaning the todo add a new date)\n",
    "- encode target variabels\n",
    "- remove columns Smoke(bad representation + small correlation value) and SCC(bad representation aswell, unsure about correlation value (0.224), have a discussion about it.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c660a27ff2af45aebf525d1dd7df941d",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 18548,
    "execution_start": 1746631709314,
    "source_hash": "634c2f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw_real_data: (477, 17)\n",
      "Shape of raw_pseudoreal_data: (1633, 17)\n",
      "Shape of synthetic_data: (20758, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "raw_pseudoreal_data = pd.read_csv(\"./datasets/real-data-20250501-154339.csv\")\n",
    "\n",
    "# Split the data into actual real data and generated with SMOTE(pseudoreal)\n",
    "raw_real_data = raw_pseudoreal_data[0:477]\n",
    "raw_pseudoreal_data = raw_pseudoreal_data[478:]\n",
    "\n",
    "# Synthetic data generated using DeepLearning model\n",
    "raw_synthetic_data = pd.read_csv(\"./datasets/synth.csv\")\n",
    "raw_synthetic_data = raw_synthetic_data.drop(columns=['id'])\n",
    "\n",
    "# Print the shape of the datasets\n",
    "print(f\"Shape of raw_real_data: {raw_real_data.shape}\")\n",
    "print(f\"Shape of raw_pseudoreal_data: {raw_pseudoreal_data.shape}\")\n",
    "print(f\"Shape of synthetic_data: {raw_synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gower distance\n",
    "to remove similar records between the pseudoreal-real dataset and synth, we use Gowers similarity measure. The function below removes the similarities between the test set and the synthetical dataset, so that information leakage can be handled accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "7b805c17835646fbb249ccb86f5e8161",
    "deepnote_cell_type": "code",
    "execution_context_id": "7ec3ed77-61ff-456b-bf4e-84847966a68b",
    "execution_millis": 0,
    "execution_start": 1746631709264,
    "source_hash": "ef234641"
   },
   "outputs": [],
   "source": [
    "# Function to remove similarities based on Gower distance\n",
    "def remove_similar(X_test, synth, threshold=.2):\n",
    "    '''\n",
    "    Remove similarities between real and synthetic data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_test : DataFrame\n",
    "        Test data\n",
    "    synth : DataFrame\n",
    "        Synthetic data\n",
    "    threshold : float, optional\n",
    "        Threshold for similarity, by default .2\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Synthetic data without similar records\n",
    "    dict\n",
    "        Map of removed records\n",
    "    '''\n",
    "    to_remove = []\n",
    "    removed_map = {}\n",
    "\n",
    "    for i, row in X_test.iterrows():\n",
    "        # Compute Gower distance between the real record and the synthetic data\n",
    "        gower_matrix = gower.gower_matrix(row.to_frame().T, synth)\n",
    "        # Find indices of synthetic records within the threshold\n",
    "        matches = np.where(gower_matrix <= threshold)\n",
    "        unique_indices = np.unique(matches[1])\n",
    "        \n",
    "        # Save the indices of the removed records\n",
    "        for idx in unique_indices:\n",
    "            removed_map.setdefault(idx, []).append(i)\n",
    "\n",
    "        # Save removed indices for later analysis (number of removed records)    \n",
    "        to_remove.extend(unique_indices)\n",
    "    \n",
    "    # Remove found similarities from synthetic data\n",
    "    synth = synth.drop(index=to_remove)\n",
    "    print(f\"Removed {len(to_remove)} similar records from synthetic data.\")\n",
    "\n",
    "    return synth, removed_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing a row since it has only 1 entry of it over all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the column 'CALC' has the value 'Always'\n",
    "filtered_data = raw_real_data[raw_real_data['CALC'] != 'Always']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data split\n",
    "we splitted the data initially between pseudoreal-real and synth data, because at this point we haven't noticed the problem with the dataset. In this format the test-set that we use for comparison is created from the pseudoreal-real dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2410 similar records from synthetic data.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets for different approaches\n",
    "# Initial approach: train on real+pseudoreal, train on real+pseudoreal+synthetic, test on split real+pseudoreal\n",
    "# Extra approach: train on real, train on real+pseudoreal, train on real+pseudoreal+synthetic, test on split real\n",
    "\n",
    "# Save all splits in a dictionary\n",
    "data = {\n",
    "    'Initial': {},\n",
    "    'Extra': {}\n",
    "}\n",
    "\n",
    "\n",
    "# Initial approach\n",
    "\n",
    "# Real + pseudoreal data based on different train/test split\n",
    "real_pseudoreal_data = pd.concat([raw_real_data, raw_pseudoreal_data])\n",
    "X_real_pseudoreal = real_pseudoreal_data.drop(columns=['NObeyesdad'])\n",
    "Y_real_pseudoreal = real_pseudoreal_data['NObeyesdad']\n",
    "X_train_real_pseudoreal, X_test_real_pseudoreal, y_train_real_pseudoreal, y_test_real_pseudoreal = train_test_split(\n",
    "    X_real_pseudoreal, Y_real_pseudoreal, test_size=TEST_SIZE, random_state=42, stratify=Y_real_pseudoreal)\n",
    "\n",
    "data['Initial']['real_train'] = {\n",
    "    'X': X_train_real_pseudoreal,\n",
    "    'y': y_train_real_pseudoreal\n",
    "}\n",
    "\n",
    "# Test split on real + pseudoreal\n",
    "data['Initial']['test'] = {\n",
    "    'X': X_test_real_pseudoreal,\n",
    "    'y': y_test_real_pseudoreal\n",
    "}\n",
    "\n",
    "# Remove similarities between real and synthetic data\n",
    "real_pseudoreal_test = pd.concat([X_test_real_pseudoreal, y_test_real_pseudoreal], axis=1)\n",
    "synthetic_data_clean, removed_map = remove_similar(real_pseudoreal_test, raw_synthetic_data)\n",
    "\n",
    "# Real + pseudoreal + synthetic train (different from the train set below)\n",
    "X_synth = synthetic_data_clean.drop(columns=['NObeyesdad'])\n",
    "y_synth = synthetic_data_clean['NObeyesdad']\n",
    "X_real_pseudoreal_synth = pd.concat([X_train_real_pseudoreal, X_synth])\n",
    "Y_real_pseudoreal_synth = pd.concat([y_train_real_pseudoreal, y_synth])\n",
    "\n",
    "\n",
    "data['Initial']['synth_train'] = {\n",
    "    'X': X_real_pseudoreal_synth,\n",
    "    'y': Y_real_pseudoreal_synth\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra data split\n",
    "In this step we split the data three ways, since we saw the flaw in the data. According to the paper we found online, where the dataset originates from:\n",
    "<ul>\n",
    "<li>entries 0-477 from \"real-data.csv\" are from a survey, we named them <strong>real</strong>.</li>\n",
    "<li>entries 478-2111 from \"real-data.csv\" are created by SMOTE to even out the target class distribution, we named them <strong>pseudoreal</strong>.</li>\n",
    "<li>the 20758 entries from \"synth.csv\" are created by a DL model, which isnt specified, so we named them <strong>synth</strong>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 628 similar records from synthetic data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extra approach\n",
    "\n",
    "X_real = raw_real_data.drop(columns=['NObeyesdad'])\n",
    "y_real = raw_real_data['NObeyesdad']\n",
    "\n",
    "# Real Real data 477, splitted\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_real, y_real, test_size=TEST_SIZE, random_state=42, stratify=y_real)\n",
    "\n",
    "data['Extra']['real_train'] = {\n",
    "    'X': X_train_real,\n",
    "    'y': y_train_real,\n",
    "}\n",
    "\n",
    "# Test split on real data only\n",
    "data['Extra']['test'] = {\n",
    "    'X': X_test_real,\n",
    "    'y': y_test_real\n",
    "}\n",
    "\n",
    "# Only pseudoreal data ~1666\n",
    "X_pseudoreal = raw_pseudoreal_data.drop(columns=['NObeyesdad'])\n",
    "y_pseudoreal = raw_pseudoreal_data['NObeyesdad']\n",
    "\n",
    "# Real + pseudoreal train\n",
    "X_pseudoreal_real = pd.concat([X_train_real, X_pseudoreal])\n",
    "y_pseudoreal_real = pd.concat([y_train_real, y_pseudoreal])\n",
    "\n",
    "data['Extra']['real_pseudoreal_train'] = {\n",
    "    'X': X_pseudoreal_real,\n",
    "    'y': y_pseudoreal_real,\n",
    "}\n",
    "\n",
    "# Remove similarities between real test data and synthetic data\n",
    "real_test = pd.concat([X_test_real, y_test_real], axis=1)\n",
    "synthetic_data_clean, removed_map = remove_similar(real_test, raw_synthetic_data)\n",
    "\n",
    "# Only synthetic data ~20k\n",
    "X_synth = synthetic_data_clean.drop(columns=['NObeyesdad'])\n",
    "y_synth = synthetic_data_clean['NObeyesdad']\n",
    "\n",
    "# Real + pseudoreal + synthetic train\n",
    "X_synth_pseudoreal_real = pd.concat([X_pseudoreal_real, X_synth])\n",
    "Y_synth_pseudoreal_real = pd.concat([y_pseudoreal_real, y_synth])\n",
    "\n",
    "\n",
    "data['Extra']['real_pseudoreal_synth_train'] = {\n",
    "    'X': X_synth_pseudoreal_real,\n",
    "    'y': Y_synth_pseudoreal_real,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the features in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for preprocessing\n",
    "\n",
    "# Numeric features with rounding to int\n",
    "numeric_features_int = ['Age']\n",
    "# Numeric features with rounding to 2 decimal places\n",
    "numeric_features_2dp = ['Height']\n",
    "# Boolean features\n",
    "boolean_features = ['family_history_with_overweight', 'FAVC', 'SCC']\n",
    "# Categorical features\n",
    "categorical_features = ['MTRANS', 'Gender']\n",
    "# Ordinal features with rounding to int\n",
    "ordinal_features_int = ['FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "# Ordinal features with mapping to int\n",
    "ordinal_features_map_int = ['CAEC', 'CALC']\n",
    "# Drop features (Just for the info)\n",
    "drop_features = ['Weight', 'SMOKE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor\n",
    "We define custom preprocessors here and also align them in a pipeline, for more clarity. Afterwards we assign them to a columntransformer, so that the preprocessing step can be done easily on multiple similar datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "\n",
    "# Numerical tranformer\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, round_type='int'):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.round_type = round_type\n",
    "        self.features = []\n",
    "    \n",
    "    def _round(self, X):\n",
    "        if self.round_type == 'int':\n",
    "            return np.round(X).astype(int)\n",
    "        elif self.round_type == 'float':\n",
    "            return np.round(X, 2)\n",
    "        return X    \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_rounded = self._round(X)\n",
    "        self.scaler.fit(X_rounded)\n",
    "        self.features = X.columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_rounded = self._round(X)\n",
    "        return self.scaler.transform(X_rounded)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.features)\n",
    "\n",
    "\n",
    "# Boolean transformer\n",
    "class BooleanTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.features = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.features = X.columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.replace({'yes': 1, 'no': 0})\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.features)\n",
    "\n",
    "\n",
    "# Ordinal transformer\n",
    "class OrdinalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rounding=False):\n",
    "        self.rounding = rounding\n",
    "        self.mapping = {\n",
    "            'no': 0,\n",
    "            'Sometimes': 1,\n",
    "            'Frequently': 2,\n",
    "            'Always': 3\n",
    "        }\n",
    "        self.features = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.features = X.columns.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.rounding:\n",
    "            return np.round(X).astype(int)\n",
    "        else:\n",
    "            return X.replace(self.mapping)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.features)\n",
    "   \n",
    "\n",
    "# Numeric int pipeline\n",
    "numeric_int_pipeline = Pipeline(steps=[\n",
    "    ('scaler_int', NumericalTransformer(round_type='int'))\n",
    "])\n",
    "\n",
    "# Numeric 2dp pipeline\n",
    "numeric_2dp_pipeline = Pipeline(steps=[\n",
    "    ('scaler_2dp', NumericalTransformer(round_type='float'))\n",
    "])\n",
    "\n",
    "# Boolean pipeline\n",
    "boolean_pipeline = Pipeline(steps=[\n",
    "    ('boolean', BooleanTransformer())\n",
    "])\n",
    "\n",
    "# Ordinal int pipeline\n",
    "ordinal_int_pipeline = Pipeline(steps=[\n",
    "    ('ordinal_int', OrdinalTransformer(rounding=True))\n",
    "])\n",
    "\n",
    "# Ordinal map int pipeline\n",
    "ordinal_map_int_pipeline = Pipeline(steps=[\n",
    "    ('ordinal_map', OrdinalTransformer(rounding=False))\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_int', numeric_int_pipeline, numeric_features_int),\n",
    "        ('numeric_2dp', numeric_2dp_pipeline, numeric_features_2dp),\n",
    "        ('boolean', boolean_pipeline, boolean_features),\n",
    "        ('ordinal_int', ordinal_int_pipeline, ordinal_features_int),\n",
    "        ('ordinal_map_int', ordinal_map_int_pipeline, ordinal_features_map_int),\n",
    "        ('categorical', categorical_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the preprocessor defined above for every training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved for Initial - real_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved for Initial - synth_train\n",
      "Preprocessed data saved for Extra - real_train\n",
      "Preprocessed data saved for Extra - real_pseudoreal_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:46: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace({'yes': 1, 'no': 0})\n",
      "c:\\Users\\denis\\Envs\\datamining\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_27500\\1731591408.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return X.replace(self.mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved for Extra - real_pseudoreal_synth_train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess the data\n",
    "for approach, datasets in data.items():\n",
    "    for name, dataset in datasets.items():\n",
    "        if 'train' in name:\n",
    "            \n",
    "            X = dataset['X']\n",
    "            # Fit the preprocessor on the training data\n",
    "            preprocessor.fit(X)\n",
    "            \n",
    "            # Transform the training and test data\n",
    "            X_train = preprocessor.transform(X)\n",
    "            X_test = preprocessor.transform(datasets['test']['X'])\n",
    "            \n",
    "\n",
    "            # Encode the target variable\n",
    "            target_map = {\n",
    "                'Insufficient_Weight': 0,\n",
    "                'Normal_Weight': 1,\n",
    "                'Overweight_Level_I': 2,\n",
    "                'Overweight_Level_II': 3,\n",
    "                'Obesity_Type_I': 4,\n",
    "                'Obesity_Type_II': 5,\n",
    "                'Obesity_Type_III': 6\n",
    "            }\n",
    "\n",
    "            y_train = pd.DataFrame(dataset['y'].replace(target_map))\n",
    "            y_test = pd.DataFrame(datasets['test']['y'].replace(target_map))\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            X_train = pd.DataFrame(X_train, columns=preprocessor.get_feature_names_out())\n",
    "            X_test = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())\n",
    "            \n",
    "            # Save the preprocessed data\n",
    "            folder = f\"./datasets/preprocessed/{approach}/{name.replace('train', 'data')}/\"\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            X_train.to_csv(os.path.join(folder, \"X_train.csv\"), index=False)\n",
    "            y_train.to_csv(os.path.join(folder, \"y_train.csv\"), index=False)\n",
    "            X_test.to_csv(os.path.join(folder, \"X_test.csv\"), index=False)\n",
    "            y_test.to_csv(os.path.join(folder, \"y_test.csv\"), index=False)\n",
    "            print(f\"Preprocessed data saved for {approach} - {name}\")\n",
    "        \n",
    "            \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "0ec939f6c6254f268bdbfe8da466167e",
  "deepnote_persisted_session": {
   "createdAt": "2025-05-07T15:51:40.796Z"
  },
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
