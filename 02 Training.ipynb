{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a534aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to try based on the results\n",
    "# 1. Random Forest Classifier\n",
    "# 2. LightGBM Classifier\n",
    "# 3. XGBoost Classifier\n",
    "# 4. Decision Tree\n",
    "# 5. KNN\n",
    "# 6. Gradient Boosting\n",
    "# 7. Naive Bayes\n",
    "# 8. Support Vector Classifier\n",
    "# 9. MLP Classifier Sklearn\n",
    "\n",
    "\n",
    "# Eval also on ROC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_validate, LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test data\n",
    "approaches = {'Initial': ['real_data', 'synth_data'], 'Extra': ['real_data', 'real_pseudoreal_data', 'real_pseudoreal_synth_data']}\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'MLP': MLPClassifier(random_state=42)\n",
    "}\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "cm = {}\n",
    "fi = {}\n",
    "\n",
    "for approach, datasets in approaches.items():\n",
    "    for dataset in datasets:\n",
    "        # Load the preprocessed data\n",
    "        X_train = pd.read_csv(f\"./datasets/preprocessed/{approach}/{dataset}/X_train.csv\")\n",
    "        y_train = pd.read_csv(f\"./datasets/preprocessed/{approach}/{dataset}/y_train.csv\")\n",
    "        X_test = pd.read_csv(f\"./datasets/preprocessed/{approach}/{dataset}/X_test.csv\")\n",
    "        y_test = pd.read_csv(f\"./datasets/preprocessed/{approach}/{dataset}/y_test.csv\")\n",
    "        \n",
    "\n",
    "        # Train the models\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Training {model_name} on {approach} - {dataset}...\")\n",
    "            if X_train.shape[0] < 500:\n",
    "                cv = LeaveOneOut()  # Use LOO for very small datasets\n",
    "            else:\n",
    "                # Count samples in smallest class\n",
    "                class_counts = y_train.value_counts()\n",
    "                min_class_samples = class_counts.min()\n",
    "                \n",
    "\n",
    "                n_splits = min(5, min_class_samples)  # Use at most 5 splits, but no more than samples in smallest class\n",
    "                cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "            \n",
    "            cv_type = 'LeaveOneOut' if isinstance(cv, LeaveOneOut) else f'StratifiedKFold with {n_splits} splits'\n",
    "            cv_results = cross_validate(model, X_train, y_train.values.ravel(), cv=cv, scoring=scoring)\n",
    "            \n",
    "            \n",
    "            # Calculate the mean and standard deviation of the scores\n",
    "            mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "            std_accuracy = np.std(cv_results['test_accuracy'])\n",
    "            mean_precision = np.mean(cv_results['test_precision'])\n",
    "            std_precision = np.std(cv_results['test_precision'])\n",
    "            mean_recall = np.mean(cv_results['test_recall'])\n",
    "            std_recall = np.std(cv_results['test_recall'])\n",
    "            mean_f1 = np.mean(cv_results['test_f1'])\n",
    "            std_f1 = np.std(cv_results['test_f1'])\n",
    "\n",
    "            \n",
    "            # Fit the model on the entire training set\n",
    "            model.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "            # Make predictions on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate the test set metrics\n",
    "            test_accuracy = accuracy_score(y_test, y_pred)\n",
    "            test_precision = precision_score(y_test, y_pred, average='macro')\n",
    "            test_recall = recall_score(y_test, y_pred, average='macro')\n",
    "            test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            test_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "            \n",
    "            results[(approach, dataset, model_name)] = {\n",
    "                'cv_type': cv_type,\t\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'test_precision': test_precision,\n",
    "                'test_recall': test_recall,\n",
    "                'test_f1': test_f1,\n",
    "                'test_roc_auc': test_roc_auc,\n",
    "            }\n",
    "            \n",
    "            # Store the confusion matrix\n",
    "            cm[(approach, dataset, model_name)] = pd.crosstab(y_test.values.ravel(), y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "            \n",
    "            # Feature importance\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                fi[(approach, dataset, model_name)] = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values(by='Importance', ascending=False)\n",
    "            elif hasattr(model, 'coef_'):\n",
    "                fi[(approach, dataset, model_name)] = pd.DataFrame({\n",
    "                    'Feature': X_train.columns,\n",
    "                    'Importance': np.abs(model.coef_[0])\n",
    "                }).sort_values(by='Importance', ascending=False)\n",
    "            else:\n",
    "                fi[(approach, dataset, model_name)] = None\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7df7315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RandomForest on Initial - real_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.8318\n",
      "Test Precision: 0.8298\n",
      "Test Recall: 0.8261\n",
      "Test F1 Score: 0.8251\n",
      "--------------------------------------------------\n",
      "Results for LightGBM on Initial - real_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.8057\n",
      "Test Precision: 0.8015\n",
      "Test Recall: 0.8038\n",
      "Test F1 Score: 0.8021\n",
      "--------------------------------------------------\n",
      "Results for XGBoost on Initial - real_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.8057\n",
      "Test Precision: 0.8012\n",
      "Test Recall: 0.8021\n",
      "Test F1 Score: 0.8013\n",
      "--------------------------------------------------\n",
      "Results for LDA on Initial - real_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.5474\n",
      "Test Precision: 0.5289\n",
      "Test Recall: 0.5335\n",
      "Test F1 Score: 0.5102\n",
      "--------------------------------------------------\n",
      "Results for KNN on Initial - real_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.7322\n",
      "Test Precision: 0.7322\n",
      "Test Recall: 0.7258\n",
      "Test F1 Score: 0.7172\n",
      "--------------------------------------------------\n",
      "Results for RandomForest on Initial - synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.7701\n",
      "Test Precision: 0.7665\n",
      "Test Recall: 0.7672\n",
      "Test F1 Score: 0.7653\n",
      "--------------------------------------------------\n",
      "Results for LightGBM on Initial - synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.7986\n",
      "Test Precision: 0.7914\n",
      "Test Recall: 0.7967\n",
      "Test F1 Score: 0.7926\n",
      "--------------------------------------------------\n",
      "Results for XGBoost on Initial - synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.7844\n",
      "Test Precision: 0.7735\n",
      "Test Recall: 0.7814\n",
      "Test F1 Score: 0.7756\n",
      "--------------------------------------------------\n",
      "Results for LDA on Initial - synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.5190\n",
      "Test Precision: 0.4949\n",
      "Test Recall: 0.5087\n",
      "Test F1 Score: 0.4877\n",
      "--------------------------------------------------\n",
      "Results for KNN on Initial - synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.7488\n",
      "Test Precision: 0.7408\n",
      "Test Recall: 0.7443\n",
      "Test F1 Score: 0.7379\n",
      "--------------------------------------------------\n",
      "Results for RandomForest on Extra - real_data:\n",
      "Cross-validation type: LeaveOneOut\n",
      "Test Accuracy: 0.5417\n",
      "Test Precision: 0.2113\n",
      "Test Recall: 0.1840\n",
      "Test F1 Score: 0.1813\n",
      "--------------------------------------------------\n",
      "Results for LightGBM on Extra - real_data:\n",
      "Cross-validation type: LeaveOneOut\n",
      "Test Accuracy: 0.4896\n",
      "Test Precision: 0.1464\n",
      "Test Recall: 0.1577\n",
      "Test F1 Score: 0.1489\n",
      "--------------------------------------------------\n",
      "Results for XGBoost on Extra - real_data:\n",
      "Cross-validation type: LeaveOneOut\n",
      "Test Accuracy: 0.4583\n",
      "Test Precision: 0.1584\n",
      "Test Recall: 0.1499\n",
      "Test F1 Score: 0.1487\n",
      "--------------------------------------------------\n",
      "Results for LDA on Extra - real_data:\n",
      "Cross-validation type: LeaveOneOut\n",
      "Test Accuracy: 0.5104\n",
      "Test Precision: 0.1054\n",
      "Test Recall: 0.1377\n",
      "Test F1 Score: 0.1155\n",
      "--------------------------------------------------\n",
      "Results for KNN on Extra - real_data:\n",
      "Cross-validation type: LeaveOneOut\n",
      "Test Accuracy: 0.4896\n",
      "Test Precision: 0.1097\n",
      "Test Recall: 0.1325\n",
      "Test F1 Score: 0.1145\n",
      "--------------------------------------------------\n",
      "Results for RandomForest on Extra - real_pseudoreal_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.5208\n",
      "Test Precision: 0.3703\n",
      "Test Recall: 0.4034\n",
      "Test F1 Score: 0.3712\n",
      "--------------------------------------------------\n",
      "Results for LightGBM on Extra - real_pseudoreal_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.5312\n",
      "Test Precision: 0.3969\n",
      "Test Recall: 0.4312\n",
      "Test F1 Score: 0.3981\n",
      "--------------------------------------------------\n",
      "Results for XGBoost on Extra - real_pseudoreal_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.4792\n",
      "Test Precision: 0.3227\n",
      "Test Recall: 0.3797\n",
      "Test F1 Score: 0.3403\n",
      "--------------------------------------------------\n",
      "Results for LDA on Extra - real_pseudoreal_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.2708\n",
      "Test Precision: 0.1627\n",
      "Test Recall: 0.1684\n",
      "Test F1 Score: 0.1548\n",
      "--------------------------------------------------\n",
      "Results for KNN on Extra - real_pseudoreal_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.3646\n",
      "Test Precision: 0.3208\n",
      "Test Recall: 0.4444\n",
      "Test F1 Score: 0.3162\n",
      "--------------------------------------------------\n",
      "Results for RandomForest on Extra - real_pseudoreal_synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.3438\n",
      "Test Precision: 0.2512\n",
      "Test Recall: 0.3192\n",
      "Test F1 Score: 0.2631\n",
      "--------------------------------------------------\n",
      "Results for LightGBM on Extra - real_pseudoreal_synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.4479\n",
      "Test Precision: 0.3281\n",
      "Test Recall: 0.3867\n",
      "Test F1 Score: 0.3260\n",
      "--------------------------------------------------\n",
      "Results for XGBoost on Extra - real_pseudoreal_synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.5312\n",
      "Test Precision: 0.3785\n",
      "Test Recall: 0.4490\n",
      "Test F1 Score: 0.3944\n",
      "--------------------------------------------------\n",
      "Results for LDA on Extra - real_pseudoreal_synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.2708\n",
      "Test Precision: 0.1874\n",
      "Test Recall: 0.2268\n",
      "Test F1 Score: 0.1816\n",
      "--------------------------------------------------\n",
      "Results for KNN on Extra - real_pseudoreal_synth_data:\n",
      "Cross-validation type: StratifiedKFold with 5 splits\n",
      "Test Accuracy: 0.3958\n",
      "Test Precision: 0.2741\n",
      "Test Recall: 0.3464\n",
      "Test F1 Score: 0.2733\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for (approach, dataset, model_name), metrics in results.items():\n",
    "    print(f\"Results for {model_name} on {approach} - {dataset}:\")\n",
    "    print(f\"Cross-validation type: {metrics['cv_type']}\")\n",
    "    print(f\"Test Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"Test Precision: {metrics['test_precision']:.4f}\")\n",
    "    print(f\"Test Recall: {metrics['test_recall']:.4f}\")\n",
    "    print(f\"Test F1 Score: {metrics['test_f1']:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04799f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrices\n",
    "for (approach, dataset, model_name), cm_df in cm.items():\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix for {model_name} on {approach} - {dataset}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c56a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "for (approach, dataset, model_name), fi_df in fi.items():\n",
    "    if fi_df is not None:\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.barplot(x='Importance', y='Feature', data=fi_df.head(10))\n",
    "        plt.title(f\"Feature Importances for {model_name} on {approach} - {dataset}\")\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === your results dict here ===\n",
    "# results = {\n",
    "#     ('Initial', 'real_data', 'ModelA'): {'test_f1': 0.72, …},\n",
    "#     ('Initial', 'real_pseudoreal_data', 'ModelA'): {'test_f1': 0.68, …},\n",
    "#     …\n",
    "# }\n",
    "\n",
    "# 1) Flatten into a DataFrame\n",
    "records = []\n",
    "for (approach, dataset, model), metrics in results.items():\n",
    "    records.append({\n",
    "        'approach': approach,\n",
    "        'dataset': dataset,\n",
    "        'model': model,\n",
    "        'f1': metrics['test_f1']\n",
    "    })\n",
    "df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# 2) Define the explicit color map for known datasets\n",
    "color_map = {\n",
    "    'real_data': 'green',\n",
    "    'real_pseudoreal_data': 'red',\n",
    "    # add other explicit mappings here…\n",
    "}\n",
    "\n",
    "# 3) Plotting helper\n",
    "def plot_approach(df, approach_name):\n",
    "    sub = df[df['approach'] == approach_name]\n",
    "    pivot = sub.pivot(index='model', columns='dataset', values='f1')\n",
    "    \n",
    "    # Build a colors list, falling back to the default cycle\n",
    "    default_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    default_iter = iter(default_cycle)\n",
    "    colors = [\n",
    "        color_map.get(ds, next(default_iter))\n",
    "        for ds in pivot.columns\n",
    "    ]\n",
    "    \n",
    "    ax = pivot.plot(\n",
    "        kind='bar',\n",
    "        figsize=(8, 6),\n",
    "        width=0.8,\n",
    "        color=colors\n",
    "    )\n",
    "    ax.set_title(f'F1 Scores — {approach_name}')\n",
    "    ax.set_ylabel('Test F1 Score')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.legend(title='Dataset')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4) Draw both charts\n",
    "plot_approach(df, 'Initial')\n",
    "plot_approach(df, 'Extra')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
